











import numpy as np  #NumPy Es un paquete de procesamiento de matrices de propósito general. Proporciona un objeto de matriz multidimensional de alto rendimiento y herramientas para trabajar con estas matrices.
import pandas as pd  #pandas Es un popular kit de herramientas de análisis de datos basado en Python. Ofrece una amplia gama de utilidades, desde el análisis de múltiples formatos de archivo hasta la conversión de una tabla de datos completa en una matriz NumPy.
import matplotlib.pyplot as plt  #matplotlib.pyplot Es una colección de funciones de estilo comando que hacen que matplotlib funcione como MATLAB. Cada función de pyplot realiza algún cambio en una figura: por ejemplo, crea una figura, crea un área de gráfico en una figura, traza líneas en un área de gráfico, decora el gráfico con etiquetas, etc.
import seaborn as sns  #Seaborn Es una biblioteca de Python utilizada principalmente para crear gráficos estadísticos. Seaborn es una biblioteca de visualización de datos basada en matplotlib y estrechamente integrada con las estructuras de datos de Pandas en Python. La visualización es la parte central de Seaborn, ya que facilita la exploración y la comprensión de los datos.
import warnings
warnings.filterwarnings("ignore")






netflix_dataset=pd.read_csv("netflix_dataset.csv")
netflix_dataset.head()


netflix_dataset.tail()


netflix_dataset.info() #vemos la informaciòn del dataset


#Identificar los valores únicos
dict = {}
for i in list(netflix_dataset.columns):
    dict[i] = netflix_dataset[i].value_counts().shape[0]
    
print(pd.DataFrame(dict,index = ["unique count"]).transpose())


#Identificar los valores únicos
dict = {}
for i in list(netflix_dataset.columns):
    dict[i] = netflix_dataset[i].value_counts().shape[0]
    
print(pd.DataFrame(dict,index = ["unique count"]).transpose())


# Valores faltantes
print('Table of missing values: ')
print(netflix_dataset.isnull().sum())








netflix_shows=netflix_dataset[netflix_dataset['type']=='TV Show']
netflix_movies=netflix_dataset[netflix_dataset['type']=='Movie']

plt.figure(figsize=(10,7))
sns.set(style="whitegrid")
ax = sns.countplot(x="type", data=netflix_dataset, palette="Set1")
ax.set_title("TV Shows VS Movies")


import matplotlib.pyplot as plt
import seaborn as sns

# Crear subconjuntos si los necesitas
netflix_shows = netflix_dataset[netflix_dataset['type'] == 'TV Show']
netflix_movies = netflix_dataset[netflix_dataset['type'] == 'Movie']

# Crear la gráfica
plt.figure(figsize=(10,7))
sns.set(style="whitegrid")
ax = sns.countplot(x="type", data=netflix_dataset, palette="Set1")

# Título
ax.set_title("TV Shows VS Movies")

# Agregar etiquetas de cantidad sobre las barras
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2., height + 10, int(height), ha="center", fontsize=12)

plt.show()






netflix_date = netflix_shows[['date_added']].dropna()
netflix_date['year'] = netflix_date['date_added'].apply(lambda x : x.split(', ')[-1])
netflix_date['month'] = netflix_date['date_added'].apply(lambda x : x.lstrip().split(' ')[0])

month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'][::-1]
df = netflix_date.groupby('year')['month'].value_counts().unstack().fillna(0)[month_order].T
plt.figure(figsize=(10, 7), dpi=200)
plt.pcolor(df, cmap='afmhot_r', edgecolors='white', linewidths=2) # heatmap
plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns, fontsize=7, fontfamily='serif')
plt.yticks(np.arange(0.5, len(df.index), 1), df.index, fontsize=7, fontfamily='serif')

plt.title('Actualización de contenidos de Netflix: Mapa de calor para análisis', fontsize=12, fontfamily='calibri', fontweight='bold', position=(0.20, 1.0+0.02))
cbar = plt.colorbar()

cbar.ax.tick_params(labelsize=8) 
cbar.ax.minorticks_on()
plt.show()





#Movie ratings analysis
plt.figure(figsize=(12,10))
sns.set(style="darkgrid")
ax = sns.countplot(x="rating", data=netflix_dataset, palette="Set1", order=netflix_dataset['rating'].value_counts().index[0:15])





imdb_ratings=pd.read_csv('IMDb ratings.csv', usecols=['weighted_average_vote'])
imdb_titles=pd.read_csv('IMDb movies.csv', usecols=['title','year','genre'])
ratings = pd.DataFrame({'Title':imdb_titles.title,
                    'Release Year':imdb_titles.year,
                    'Rating': imdb_ratings.weighted_average_vote,
                    'Genre':imdb_titles.genre})
ratings.drop_duplicates(subset=['Title','Release Year','Rating'], inplace=True)
ratings.shape


ratings.dropna()
joint_data=ratings.merge(netflix_dataset,left_on='Title',right_on='title',how='inner')
joint_data=joint_data.sort_values(by='Rating', ascending=False)





#Las 10 películas mejor valoradas en Netflix son:
import plotly.express as px
top_rated=joint_data[0:10]
fig =px.sunburst(
    top_rated,
    path=['title','country'],
    values='Rating',
    color='Rating')
fig.show()





#Top countries creating contents
country_count=joint_data['country'].value_counts().sort_values(ascending=False)
country_count=pd.DataFrame(country_count)
topcountries=country_count[0:11]
topcountries





Last_fifteen_years = netflix_dataset[netflix_dataset['release_year']>2005 ]
Last_fifteen_years.head()


#Year wise analysis
plt.figure(figsize=(12,10))
sns.set(style="darkgrid")
ax = sns.countplot(y="release_year", data=Last_fifteen_years, palette="Set1", order=netflix_dataset['release_year'].value_counts().index[0:15])





#Analysis of TV Shows in Netflix

countries={}
netflix_shows['country']=netflix_shows['country'].fillna('Unknown')
cou=list(netflix_shows['country'])
for i in cou:
    #print(i)
    i=list(i.split(','))
    if len(i)==1:
        if i in list(countries.keys()):
            countries[i]+=1
        else:
            countries[i[0]]=1
    else:
        for j in i:
            if j in list(countries.keys()):
                countries[j]+=1
            else:
                countries[j]=1


countries_fin={}
for country,no in countries.items():
    country=country.replace(' ','')
    if country in list(countries_fin.keys()):
        countries_fin[country]+=no
    else:
        countries_fin[country]=no
        
countries_fin={k: v for k, v in sorted(countries_fin.items(), key=lambda item: item[1], reverse= True)}


# Top 10 TV shows creating countries.

plt.figure(figsize=(8,8))
ax = sns.barplot(x=list(countries_fin.keys())[0:10],y=list(countries_fin.values())[0:10])
ax.set_xticklabels(list(countries_fin.keys())[0:10],rotation = 90)





#Analysis of duration of movies

netflix_movies['duration']=netflix_movies['duration'].str.replace(' min','')
netflix_movies['duration']=netflix_movies['duration'].astype(str).astype(int)
netflix_movies['duration']


sns.set(style="darkgrid")
ax=sns.kdeplot(data=netflix_movies['duration'], shade=True)





#Analysis of duration of TV shows

features=['title','duration']
durations= netflix_shows[features]

durations['no_of_seasons']=durations['duration'].str.replace(' Season','')

#durations['no_of_seasons']=durations['no_of_seasons'].astype(str).astype(int)
durations['no_of_seasons']=durations['no_of_seasons'].str.replace('s','')
durations['no_of_seasons']=durations['no_of_seasons'].astype(str).astype(int)
#TV shows with largest number of seasons
t=['title','no_of_seasons']
top=durations[t]

top=top.sort_values(by='no_of_seasons', ascending=False)
top20=top[0:20]
top20.plot(kind='bar',x='title',y='no_of_seasons', color='blue')





#Recomendador basado en descripción de la trama (Recomendaciones basadas en contenido)

netflix_dataset['description'].head()


#Sistema de recomendación (basado en contenido)
#Importar TfIdfVectorizer desde scikit-learn

from sklearn.feature_extraction.text import TfidfVectorizer

#Defina un objeto vectorizador TF-IDF. Elimine todas las palabras vacías en inglés, como "the", "a", etc.
tfidf = TfidfVectorizer(stop_words='english')

#Replace NaN with an empty string
netflix_dataset['description'] = netflix_dataset['description'].fillna('')

#Reemplace NaN con una cadena vacía
tfidf_matrix = tfidf.fit_transform(netflix_dataset['description'])

#Salida de la forma de tfidf_matrix
tfidf_matrix.shape


#Import linear_kernel
from sklearn.metrics.pairwise import linear_kernel

# Calcular la matriz de similitud de coseno
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)


#Construir un mapa inverso de índices y títulos de películas
indices = pd.Series(netflix_dataset.index, index=netflix_dataset['title']).drop_duplicates()


# Función que toma el título de la película como entrada y genera la mayoría de las películas similares
def get_recommendations(title, cosine_sim=cosine_sim):
    # Obtener el índice de la película que coincide con el título
    idx = indices[title]

    # Obtenga las puntuaciones de similitud de pares de todas las películas con esa película
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Ordena las películas según los puntajes de similitud
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Obtén las puntuaciones de las 10 películas más similares
    sim_scores = sim_scores[1:11]

    # Obtener los índices de la película
    movie_indices = [i[0] for i in sim_scores]

    # Devuelve el top 10 de películas más similares
    return netflix_dataset['title'].iloc[movie_indices]


get_recommendations('Welcome')


get_recommendations('Avengers: Infinity War')


get_recommendations('Dil Dhadakne Do')


#Rellenar valores nulos con una cadena vacía.
filledna=netflix_dataset.fillna('')
filledna.head()


#Limpieza de datos: convertir todas las palabras en minúsculas
def clean_data(x):
        return str.lower(x.replace(" ", ""))


#Identificar las características sobre las que se filtrará el modelo.
features=['title','director','cast','listed_in','description']
filledna=filledna[features]
for feature in features:
    filledna[feature] = filledna[feature].apply(clean_data)
    
filledna.head()


#Rellenar valores nulos con una cadena vacía.
filledna=netflix_dataset.fillna('')
filledna.head()

#Limpieza de datos: convertir todas las palabras en minúsculas
def clean_data(x):
        return str.lower(x.replace(" ", ""))

#Identificar las características sobre las que se filtrará el modelo.
features=['title','director','cast','listed_in','description']
filledna=filledna[features]

for feature in features:
    filledna[feature] = filledna[feature].apply(clean_data)
    
filledna.head()

def create_soup(x):
    return x['title']+ ' ' + x['director'] + ' ' + x['cast'] + ' ' +x['listed_in']+' '+ x['description']

filledna['soup'] = filledna.apply(create_soup, axis=1)


# Importa CountVectorizer y crea la matriz de conteo
from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(filledna['soup'])


# Calcule la matriz de similitud de coseno basándose en count_matrix
from sklearn.metrics.pairwise import cosine_similarity

cosine_sim2 = cosine_similarity(count_matrix, count_matrix)


# Restablecer el índice de nuestro DataFrame principal y construir un mapeo inverso como antes
filledna=filledna.reset_index()
indices = pd.Series(filledna.index, index=filledna['title'])


def get_recommendations_new(title, cosine_sim=cosine_sim):
    title=title.replace(' ','').lower()
    idx = indices[title]

    # Obtenga las puntuaciones de similitud de pares de todas las películas con esa película
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Ordena las películas según los puntajes de similitud
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Obtén las puntuaciones de las 10 películas más similares
    sim_scores = sim_scores[1:11]

    # Obtener los índices de la película
    movie_indices = [i[0] for i in sim_scores]

    # Devuelve el top 10 de películas más similares
    return netflix_dataset['title'].iloc[movie_indices]


get_recommendations_new('Welcome', cosine_sim2)


get_recommendations_new('Avengers: Infinity War', cosine_sim2)


get_recommendations_new('Dil Dhadakne Do', cosine_sim2)


# 1. Filtrar títulos desde 2006 en adelante
Last_fifteen_years = netflix_dataset[netflix_dataset['release_year'] > 2005]

# 2. Contar cuántos títulos por año
plt.figure(figsize=(12, 6))
sns.set(style="whitegrid")
ax = sns.countplot(data=Last_fifteen_years, x='release_year', palette='coolwarm', order=sorted(Last_fifteen_years['release_year'].value_counts().index))

# 3. Agregar etiquetas de cantidad sobre las barras
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2., height + 5, int(height), ha='center', fontsize=9)

# 4. Estética y presentación
plt.title('Cantidad de contenidos por año de liberación (desde 2006)', fontsize=14)
plt.xlabel('Año de liberación')
plt.ylabel('Número de títulos')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()





# Leer ambos archivos CSV
movies_df = pd.read_csv("netflix_movies_detailed_up_to_2025.csv")
tv_shows_df = pd.read_csv("netflix_tv_shows_detailed_up_to_2025.csv")

# Concatenar ambos DataFrames
netflix_dataset2c = pd.concat([movies_df, tv_shows_df], ignore_index=True)

# Ver las primeras filas del dataset combinado
netflix_dataset2c.head()


netflix_dataset2c.info()


#Identificar los valores únicos
dict = {}
for i in list(netflix_dataset2c.columns):
    dict[i] = netflix_dataset2c[i].value_counts().shape[0]
    
print(pd.DataFrame(dict,index = ["unique count"]).transpose())


# Valores faltantes
print('Table of missing values: ')
print(netflix_dataset2c.isnull().sum())








netflix_shows=netflix_dataset2c[netflix_dataset2c['type']=='TV Show']
netflix_movies=netflix_dataset2c[netflix_dataset2c['type']=='Movie']

plt.figure(figsize=(10,7))
sns.set(style="whitegrid")
ax = sns.countplot(x="type", data=netflix_dataset2c, palette="Set1")
ax.set_title("TV Shows VS Movies")


# Crear subconjuntos si los necesitas
netflix_shows = netflix_dataset2c[netflix_dataset2c['type'] == 'TV Show']
netflix_movies = netflix_dataset2c[netflix_dataset2c['type'] == 'Movie']

# Crear la gráfica
plt.figure(figsize=(10,7))
sns.set(style="whitegrid")
ax = sns.countplot(x="type", data=netflix_dataset2c, palette="Set1")

# Título
ax.set_title("TV Shows VS Movies")

# Agregar etiquetas de cantidad sobre las barras
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2., height + 10, int(height), ha="center", fontsize=12)

plt.show()





netflix_date = netflix_shows[['date_added']].dropna()
netflix_date['year'] = netflix_date['date_added'].apply(lambda x : x.split(', ')[-1])
netflix_date['month'] = netflix_date['date_added'].apply(lambda x : x.lstrip().split(' ')[0])

month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'][::-1]
df = netflix_date.groupby('year')['month'].value_counts().unstack().fillna(0)[month_order].T
plt.figure(figsize=(10, 7), dpi=200)
plt.pcolor(df, cmap='afmhot_r', edgecolors='white', linewidths=2) # heatmap
plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns, fontsize=7, fontfamily='serif')
plt.yticks(np.arange(0.5, len(df.index), 1), df.index, fontsize=7, fontfamily='serif')

plt.title('Actualización de contenidos de Netflix: Mapa de calor para análisis', fontsize=12, fontfamily='calibri', fontweight='bold', position=(0.20, 1.0+0.02))
cbar = plt.colorbar()

cbar.ax.tick_params(labelsize=8) 
cbar.ax.minorticks_on()
plt.show()












