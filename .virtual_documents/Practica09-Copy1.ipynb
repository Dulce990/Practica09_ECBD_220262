











import numpy as np  #NumPy Es un paquete de procesamiento de matrices de propósito general. Proporciona un objeto de matriz multidimensional de alto rendimiento y herramientas para trabajar con estas matrices.
import pandas as pd  #pandas Es un popular kit de herramientas de análisis de datos basado en Python. Ofrece una amplia gama de utilidades, desde el análisis de múltiples formatos de archivo hasta la conversión de una tabla de datos completa en una matriz NumPy.
import matplotlib.pyplot as plt  #matplotlib.pyplot Es una colección de funciones de estilo comando que hacen que matplotlib funcione como MATLAB. Cada función de pyplot realiza algún cambio en una figura: por ejemplo, crea una figura, crea un área de gráfico en una figura, traza líneas en un área de gráfico, decora el gráfico con etiquetas, etc.
import seaborn as sns  #Seaborn Es una biblioteca de Python utilizada principalmente para crear gráficos estadísticos. Seaborn es una biblioteca de visualización de datos basada en matplotlib y estrechamente integrada con las estructuras de datos de Pandas en Python. La visualización es la parte central de Seaborn, ya que facilita la exploración y la comprensión de los datos.
import warnings
warnings.filterwarnings("ignore")






# Leer ambos archivos CSV
movies_df = pd.read_csv("netflix_movies_detailed_up_to_2025.csv")
tv_shows_df = pd.read_csv("netflix_tv_shows_detailed_up_to_2025.csv")

# Concatenar ambos DataFrames
netflix_dataset = pd.concat([movies_df, tv_shows_df], ignore_index=True)

# Ver las primeras filas del dataset combinado
netflix_dataset.head()


netflix_dataset.info()


#Identificar los valores únicos
dict = {}
for i in list(netflix_dataset.columns):
    dict[i] = netflix_dataset[i].value_counts().shape[0]
    
print(pd.DataFrame(dict,index = ["unique count"]).transpose())


# Valores faltantes
print('Table of missing values: ')
print(netflix_dataset.isnull().sum())








netflix_shows=netflix_dataset[netflix_dataset['type']=='TV Show']
netflix_movies=netflix_dataset[netflix_dataset['type']=='Movie']

plt.figure(figsize=(10,7))
sns.set(style="whitegrid")
ax = sns.countplot(x="type", data=netflix_dataset, palette="Set1")
ax.set_title("TV Shows VS Movies")


# Crear subconjuntos si los necesitas
netflix_shows = netflix_dataset[netflix_dataset['type'] == 'TV Show']
netflix_movies = netflix_dataset[netflix_dataset['type'] == 'Movie']

# Crear la gráfica
plt.figure(figsize=(10,7))
sns.set(style="whitegrid")
ax = sns.countplot(x="type", data=netflix_dataset, palette="Set1")

# Título
ax.set_title("TV Shows VS Movies")

# Agregar etiquetas de cantidad sobre las barras
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2., height + 10, int(height), ha="center", fontsize=12)

plt.show()





# 1) Convierte a datetime
netflix_date['date_added'] = pd.to_datetime(netflix_date['date_added'])

# 2) Saca año y mes
netflix_date['year']  = netflix_date['date_added'].dt.year.astype(str)
netflix_date['month'] = netflix_date['date_added'].dt.month_name()

# 3) Orden de meses (de diciembre a enero)
month_order = [
    'December','November','October','September','August','July',
    'June','May','April','March','February','January'
]

# 4) Agrupa y reindexa para asegurarte de tener todas las columnas de mes
df2 = (
    netflix_date
      .groupby('year')['month']
      .value_counts()
      .unstack(fill_value=0)
      .reindex(columns=month_order, fill_value=0)
      .T
)

# 5) Dibuja el mapa de calor
import numpy as np
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 7), dpi=200)
plt.pcolor(df2, cmap='afmhot_r', edgecolors='white', linewidths=2)
plt.xticks(np.arange(0.5, len(df2.columns), 1), df2.columns, fontsize=7)
plt.yticks(np.arange(0.5, len(df2.index), 1), df2.index, fontsize=7)
plt.title('Actualización de contenidos de Netflix: Mapa de calor', pad=20)
plt.colorbar().ax.tick_params(labelsize=8)
plt.show()






plt.figure(figsize=(12,10))
sns.set(style="darkgrid")
ax = sns.countplot(x="rating", data=netflix_dataset, palette="Set1", order=netflix_dataset['rating'].value_counts().index[0:15])





imdb_ratings=pd.read_csv('IMDb ratings.csv', usecols=['weighted_average_vote'])
imdb_titles=pd.read_csv('IMDb movies.csv', usecols=['title','year','genre'])
ratings = pd.DataFrame({'Title':imdb_titles.title,
                    'Release Year':imdb_titles.year,
                    'Rating': imdb_ratings.weighted_average_vote,
                    'Genre':imdb_titles.genre})
ratings.drop_duplicates(subset=['Title','Release Year','Rating'], inplace=True)
ratings.shape


ratings.dropna()
joint_data=ratings.merge(netflix_dataset,left_on='Title',right_on='title',how='inner')
joint_data=joint_data.sort_values(by='Rating', ascending=False)





import plotly.express as px
top_rated=joint_data[0:10]
fig =px.sunburst(
    top_rated,
    path=['title','country'],
    values='Rating',
    color='Rating')
fig.show()





country_count=joint_data['country'].value_counts().sort_values(ascending=False)
country_count=pd.DataFrame(country_count)
topcountries=country_count[0:11]
topcountries





Last_fifteen_years = netflix_dataset[netflix_dataset['release_year']>2005 ]
Last_fifteen_years.head()


#Análisis anual
plt.figure(figsize=(12,10))
sns.set(style="darkgrid")
ax = sns.countplot(y="release_year", data=Last_fifteen_years, palette="Set1", order=netflix_dataset['release_year'].value_counts().index[0:15])





countries={}
netflix_shows['country']=netflix_shows['country'].fillna('Unknown')
cou=list(netflix_shows['country'])
for i in cou:
    #print(i)
    i=list(i.split(','))
    if len(i)==1:
        if i in list(countries.keys()):
            countries[i]+=1
        else:
            countries[i[0]]=1
    else:
        for j in i:
            if j in list(countries.keys()):
                countries[j]+=1
            else:
                countries[j]=1


countries_fin={}
for country,no in countries.items():
    country=country.replace(' ','')
    if country in list(countries_fin.keys()):
        countries_fin[country]+=no
    else:
        countries_fin[country]=no
        
countries_fin={k: v for k, v in sorted(countries_fin.items(), key=lambda item: item[1], reverse= True)}


# Los 10 mejores países creadores de programas de televisión.

plt.figure(figsize=(8,8))
ax = sns.barplot(x=list(countries_fin.keys())[0:10],y=list(countries_fin.values())[0:10])
ax.set_xticklabels(list(countries_fin.keys())[0:10],rotation = 90)





nums = netflix_movies['duration'].astype(str).str.extract(r'(\d+)', expand=False)

# 2) Convierte a numérico, dejando NaN donde no hubiera dígitos
netflix_movies['duration'] = pd.to_numeric(nums, errors='coerce')

# 3) Si quieres 0 en lugar de NaN, rellénalos; si prefieres, puedes dropna() en vez de fillna()
netflix_movies['duration'] = netflix_movies['duration'].fillna(0).astype(int)

# Comprueba
print(netflix_movies['duration'].head(10))
print("Filas totales:", len(netflix_movies))
print("Valores nulos en duration:", netflix_movies['duration'].isnull().sum())


sns.set(style="darkgrid")
ax=sns.kdeplot(data=netflix_movies['duration'], shade=True)





features=['title','duration']
durations= netflix_shows[features]

durations['no_of_seasons']=durations['duration'].str.replace(' Season','')

#durations['no_of_seasons']=durations['no_of_seasons'].astype(str).astype(int)
durations['no_of_seasons']=durations['no_of_seasons'].str.replace('s','')


durations['no_of_seasons']=durations['no_of_seasons'].astype(str).astype(int)


#Programas de TV con mayor número de temporadas
t=['title','no_of_seasons']
top=durations[t]
top=top.sort_values(by='no_of_seasons', ascending=False)


top20=top[0:20]
top20.plot(kind='bar',x='title',y='no_of_seasons', color='blue')








netflix_dataset['description'].head()


#Recommedation System(Content Based)

#Importar TfIdfVectorizer desde scikit-learn
from sklearn.feature_extraction.text import TfidfVectorizer

#Defina un objeto vectorizador TF-IDF. Elimine todas las palabras vacías en inglés, como "the", "a", etc.
tfidf = TfidfVectorizer(stop_words='english')

#Reemplace NaN con una cadena vacía
netflix_dataset['description'] = netflix_dataset['description'].fillna('')

#Construya la matriz TF-IDF requerida ajustando y transformando los datos
tfidf_matrix = tfidf.fit_transform(netflix_dataset['description'])

#Salida de la forma de tfidf_matrix
tfidf_matrix.shape


#Importar linear_kernel
from sklearn.metrics.pairwise import linear_kernel

# Calcular la matriz de similitud de coseno
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)


#Construir un mapa inverso de índices y títulos de películas
indices = pd.Series(netflix_dataset.index, index=netflix_dataset['title']).drop_duplicates()


# Función que toma el título de la película como entrada y genera la mayoría de las películas similares
def get_recommendations2(title, cosine_sim=cosine_sim):
    # Obtener el índice de la película que coincide con el título
    idx = indices[title]

    # Obtenga las puntuaciones de similitud de pares de todas las películas con esa película
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Ordena las películas según los puntajes de similitud
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

   # Obtén las puntuaciones de las 10 películas más similares
    sim_scores = sim_scores[1:11]

    # Obtener los índices de la película
    movie_indices = [i[0] for i in sim_scores]

    # Devuelve el top 10 de películas más similares
    return netflix_dataset['title'].iloc[movie_indices]


get_recommendations2('Welcome to the South')


get_recommendations2('Avengers: Infinity War')


get_recommendations2('Dil Dhadakne Do')


get_recommendations2("Pan's Labyrinth")


get_recommendations2("Up")


get_recommendations2("Chernobyl")


get_recommendations2("The Boys")


#Rellenar valores nulos con una cadena vacía.
filledna=netflix_dataset.fillna('')
filledna.head()


#Limpieza de datos: convertir todas las palabras en minúsculas
def clean_data(x):
        return str.lower(x.replace(" ", ""))


#Identificar las características sobre las que se filtrará el modelo.
features=['title','director','cast','description']
filledna=filledna[features]


for feature in features:
    filledna[feature] = filledna[feature].apply(clean_data)
    
filledna.head()


def create_soup(x):
    return x['title']+ ' ' + x['director'] + ' ' + x['cast'] + ' ' + x['description']

filledna['soup'] = filledna.apply(create_soup, axis=1)


# Importa CountVectorizer y crea la matriz de conteo
from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(filledna['soup'])


# Calcule la matriz de similitud de coseno basándose en count_matrix
from sklearn.metrics.pairwise import cosine_similarity

cosine_sim2 = cosine_similarity(count_matrix, count_matrix)


# Restablecer el índice de nuestro DataFrame principal y construir un mapeo inverso como antes
filledna=filledna.reset_index()
indices = pd.Series(filledna.index, index=filledna['title'])


def get_recommendations_new2(title, cosine_sim=cosine_sim):
    title=title.replace(' ','').lower()
    idx = indices[title]

    # Obtenga las puntuaciones de similitud de pares de todas las películas con esa película
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Ordena las películas según los puntajes de similitud
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Obtén las puntuaciones de las 10 películas más similares
    sim_scores = sim_scores[1:11]

   # Obtener los índices de la película
    movie_indices = [i[0] for i in sim_scores]

    # Devuelve el top 10 de películas más similares
    return netflix_dataset['title'].iloc[movie_indices]


get_recommendations_new2('Welcome to the South', cosine_sim2)


get_recommendations_new2('Avengers: Infinity War', cosine_sim2)


get_recommendations_new2('Dil Dhadakne Do', cosine_sim2)


get_recommendations_new2("Pan's Labyrinth", cosine_sim2)


get_recommendations_new2("Up")


get_recommendations_new2("Chernobyl")


get_recommendations_new2("The Boys")
