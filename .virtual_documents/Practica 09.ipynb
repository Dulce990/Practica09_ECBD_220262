





import numpy as np  #NumPy is a general-purpose array-processing package. It provides a high-performance multidimensional array object, and tools for working with these arrays.
import pandas as pd  #pandas is a popular Python-based data analysis toolkit. It presents a diverse range of utilities, ranging from parsing multiple file formats to converting an entire data table into a NumPy matrix array.
import matplotlib.pyplot as plt  #matplotlib.pyplot is a collection of command style functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc.
import seaborn as sns  #Seaborn is a library in Python predominantly used for making statistical graphics. Seaborn is a data visualization library built on top of matplotlib and closely integrated with pandas data structures in Python. Visualization is the central part of Seaborn which helps in exploration and understanding of data.
import warnings
warnings.filterwarnings("ignore")








netflix_dataset=pd.read_csv("netflix_dataset.csv")
netflix_dataset.head()


netflix_dataset.info()


#Identify the unique values
dict = {}
for i in list(netflix_dataset.columns):
    dict[i] = netflix_dataset[i].value_counts().shape[0]
    
print(pd.DataFrame(dict,index = ["unique count"]).transpose())


# Missing values
print('Table of missing values: ')
print(netflix_dataset.isnull().sum())








netflix_shows=netflix_dataset[netflix_dataset['type']=='TV Show']
netflix_movies=netflix_dataset[netflix_dataset['type']=='Movie']

plt.figure(figsize=(10,7))
sns.set(style="whitegrid")
ax = sns.countplot(x="type", data=netflix_dataset, palette="Set1")
ax.set_title("TV Shows VS Movies")





netflix_date = netflix_shows[['date_added']].dropna()
netflix_date['year'] = netflix_date['date_added'].apply(lambda x : x.split(', ')[-1])
netflix_date['month'] = netflix_date['date_added'].apply(lambda x : x.lstrip().split(' ')[0])

month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'][::-1]
df = netflix_date.groupby('year')['month'].value_counts().unstack().fillna(0)[month_order].T
plt.figure(figsize=(10, 7), dpi=200)
plt.pcolor(df, cmap='afmhot_r', edgecolors='white', linewidths=2) # heatmap
plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns, fontsize=7, fontfamily='serif')
plt.yticks(np.arange(0.5, len(df.index), 1), df.index, fontsize=7, fontfamily='serif')

plt.title('Netflix Contents Update - HeatMap for Analysis', fontsize=12, fontfamily='calibri', fontweight='bold', position=(0.20, 1.0+0.02))
cbar = plt.colorbar()

cbar.ax.tick_params(labelsize=8) 
cbar.ax.minorticks_on()
plt.show()





#Movie ratings analysis
plt.figure(figsize=(12,10))
sns.set(style="darkgrid")
ax = sns.countplot(x="rating", data=netflix_dataset, palette="Set1", order=netflix_dataset['rating'].value_counts().index[0:15])





imdb_ratings=pd.read_csv('IMDb ratings.csv', usecols=['weighted_average_vote'])
imdb_titles=pd.read_csv('IMDb movies.csv', usecols=['title','year','genre'])
ratings = pd.DataFrame({'Title':imdb_titles.title,
                    'Release Year':imdb_titles.year,
                    'Rating': imdb_ratings.weighted_average_vote,
                    'Genre':imdb_titles.genre})
ratings.drop_duplicates(subset=['Title','Release Year','Rating'], inplace=True)
ratings.shape


ratings.dropna()
joint_data=ratings.merge(netflix_dataset,left_on='Title',right_on='title',how='inner')
joint_data=joint_data.sort_values(by='Rating', ascending=False)





#Top rated 10 movies in Netflix are:
import plotly.express as px
top_rated=joint_data[0:10]
fig =px.sunburst(
    top_rated,
    path=['title','country'],
    values='Rating',
    color='Rating')
fig.show()





#Top countries creating contents
country_count=joint_data['country'].value_counts().sort_values(ascending=False)
country_count=pd.DataFrame(country_count)
topcountries=country_count[0:11]
topcountries





Last_fifteen_years = netflix_dataset[netflix_dataset['release_year']>2005 ]
Last_fifteen_years.head()


#Year wise analysis
plt.figure(figsize=(12,10))
sns.set(style="darkgrid")
ax = sns.countplot(y="release_year", data=Last_fifteen_years, palette="Set1", order=netflix_dataset['release_year'].value_counts().index[0:15])





#Analysis of TV Shows in Netflix

countries={}
netflix_shows['country']=netflix_shows['country'].fillna('Unknown')
cou=list(netflix_shows['country'])
for i in cou:
    #print(i)
    i=list(i.split(','))
    if len(i)==1:
        if i in list(countries.keys()):
            countries[i]+=1
        else:
            countries[i[0]]=1
    else:
        for j in i:
            if j in list(countries.keys()):
                countries[j]+=1
            else:
                countries[j]=1


countries_fin={}
for country,no in countries.items():
    country=country.replace(' ','')
    if country in list(countries_fin.keys()):
        countries_fin[country]+=no
    else:
        countries_fin[country]=no
        
countries_fin={k: v for k, v in sorted(countries_fin.items(), key=lambda item: item[1], reverse= True)}


# Top 10 TV shows creating countries.

plt.figure(figsize=(8,8))
ax = sns.barplot(x=list(countries_fin.keys())[0:10],y=list(countries_fin.values())[0:10])
ax.set_xticklabels(list(countries_fin.keys())[0:10],rotation = 90)





#Analysis of duration of movies

netflix_movies['duration']=netflix_movies['duration'].str.replace(' min','')
netflix_movies['duration']=netflix_movies['duration'].astype(str).astype(int)
netflix_movies['duration']


sns.set(style="darkgrid")
ax=sns.kdeplot(data=netflix_movies['duration'], shade=True)





#Analysis of duration of TV shows

features=['title','duration']
durations= netflix_shows[features]

durations['no_of_seasons']=durations['duration'].str.replace(' Season','')

#durations['no_of_seasons']=durations['no_of_seasons'].astype(str).astype(int)
durations['no_of_seasons']=durations['no_of_seasons'].str.replace('s','')


durations['no_of_seasons']=durations['no_of_seasons'].astype(str).astype(int)


#TV shows with largest number of seasons
t=['title','no_of_seasons']
top=durations[t]

top=top.sort_values(by='no_of_seasons', ascending=False)


top20=top[0:20]
top20.plot(kind='bar',x='title',y='no_of_seasons', color='blue')





#Plot description based Recommender (Content Based Recommendations)

netflix_dataset['description'].head()


#Recommedation System(Content Based)

#Import TfIdfVectorizer from scikit-learn
from sklearn.feature_extraction.text import TfidfVectorizer

#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a', etc.
tfidf = TfidfVectorizer(stop_words='english')

#Replace NaN with an empty string
netflix_dataset['description'] = netflix_dataset['description'].fillna('')

#Construct the required TF-IDF matrix by fitting and transforming the data
tfidf_matrix = tfidf.fit_transform(netflix_dataset['description'])

#Output the shape of tfidf_matrix
tfidf_matrix.shape


#Import linear_kernel
from sklearn.metrics.pairwise import linear_kernel

# Compute the cosine similarity matrix
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)


#Construct a reverse map of indices and movie titles
indices = pd.Series(netflix_dataset.index, index=netflix_dataset['title']).drop_duplicates()


# Function that takes in movie title as input and outputs most similar movies
def get_recommendations(title, cosine_sim=cosine_sim):
    # Get the index of the movie that matches the title
    idx = indices[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar movies
    sim_scores = sim_scores[1:11]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies
    return netflix_dataset['title'].iloc[movie_indices]


get_recommendations('Welcome')


get_recommendations('Avengers: Infinity War')


get_recommendations('Dil Dhadakne Do')


#Filling null values with empty string.
filledna=netflix_dataset.fillna('')
filledna.head()


#Cleaning the data - making all the words lower case
def clean_data(x):
        return str.lower(x.replace(" ", ""))


#Identifying features on which the model is to be filtered.
features=['title','director','cast','listed_in','description']
filledna=filledna[features]


for feature in features:
    filledna[feature] = filledna[feature].apply(clean_data)
    
filledna.head()


def create_soup(x):
    return x['title']+ ' ' + x['director'] + ' ' + x['cast'] + ' ' +x['listed_in']+' '+ x['description']

filledna['soup'] = filledna.apply(create_soup, axis=1)


# Import CountVectorizer and create the count matrix
from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(filledna['soup'])


# Compute the Cosine Similarity matrix based on the count_matrix
from sklearn.metrics.pairwise import cosine_similarity

cosine_sim2 = cosine_similarity(count_matrix, count_matrix)


# Reset index of our main DataFrame and construct reverse mapping as before
filledna=filledna.reset_index()
indices = pd.Series(filledna.index, index=filledna['title'])


def get_recommendations_new(title, cosine_sim=cosine_sim):
    title=title.replace(' ','').lower()
    idx = indices[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar movies
    sim_scores = sim_scores[1:11]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies
    return netflix_dataset['title'].iloc[movie_indices]


get_recommendations_new('Welcome', cosine_sim2)


get_recommendations_new('Avengers: Infinity War', cosine_sim2)


get_recommendations_new('Dil Dhadakne Do', cosine_sim2)





# Cargar ambas bases de datos
netflix_movies = pd.read_csv("netflix_movies_detailed_up_to_2025.csv")
netflix_tv_shows = pd.read_csv("netflix_tv_shows_detailed_up_to_2025.csv")

# Concatenarlas en un solo DataFrame
netflix_df = pd.concat([netflix_movies, netflix_tv_shows], ignore_index=True)

# Mostrar las primeras filas
netflix_df.head()


netflix_df.info()


#Identify the unique values
dict = {}
for i in list(netflix_df.columns):
    dict[i] = netflix_df[i].value_counts().shape[0]
    
print(pd.DataFrame(dict,index = ["unique count"]).transpose())


# Missing values
print('Table of missing values: ')
print(netflix_df.isnull().sum())








netflix_shows=netflix_df[netflix_df['type']=='TV Show']
netflix_movies=netflix_df[netflix_df['type']=='Movie']

plt.figure(figsize=(10,7))
sns.set(style="whitegrid")
ax = sns.countplot(x="type", data=netflix_df, palette="Set1")
ax.set_title("TV Shows VS Movies")





# Paso 1: Limpiar y extraer año y mes
netflix_date = netflix_df[['date_added']].dropna()
netflix_date['date_added'] = pd.to_datetime(netflix_date['date_added'])

# Extraer año y nombre del mes
netflix_date['year'] = netflix_date['date_added'].dt.year.astype(str)
netflix_date['month'] = netflix_date['date_added'].dt.month_name()

# Paso 2: Crear orden correcto (de diciembre a enero)
month_order = ['December', 'November', 'October', 'September', 'August', 'July', 
               'June', 'May', 'April', 'March', 'February', 'January']

# Paso 3: Agrupar y reorganizar
df_heatmap = (
    netflix_date
    .groupby('year')['month']
    .value_counts()
    .unstack()
    .fillna(0)
    .reindex(columns=month_order, fill_value=0)
    .T
)

# Paso 4: Graficar heatmap
plt.figure(figsize=(10, 7), dpi=200)
plt.pcolor(df_heatmap, cmap='afmhot_r', edgecolors='white', linewidths=2)

plt.xticks(np.arange(0.5, len(df_heatmap.columns), 1), df_heatmap.columns, fontsize=7, fontfamily='serif')
plt.yticks(np.arange(0.5, len(df_heatmap.index), 1), df_heatmap.index, fontsize=7, fontfamily='serif')

plt.title('Netflix Contents Update - HeatMap for Analysis', fontsize=12, fontfamily='calibri', fontweight='bold', position=(0.20, 1.02))
cbar = plt.colorbar()
cbar.ax.tick_params(labelsize=8)
cbar.ax.minorticks_on()
plt.show()







#Movie ratings analysis
plt.figure(figsize=(12,10))
sns.set(style="darkgrid")
ax = sns.countplot(x="rating", data=netflix_df, palette="Set1", order=netflix_df['rating'].value_counts().index[0:15])





imdb_ratings=pd.read_csv('IMDb ratings.csv', usecols=['weighted_average_vote'])
imdb_titles=pd.read_csv('IMDb movies.csv', usecols=['title','year','genre'])
ratings = pd.DataFrame({'Title':imdb_titles.title,
                    'Release Year':imdb_titles.year,
                    'Rating': imdb_ratings.weighted_average_vote,
                    'Genre':imdb_titles.genre})
ratings.drop_duplicates(subset=['Title','Release Year','Rating'], inplace=True)
ratings.shape


ratings.dropna()
joint_data=ratings.merge(netflix_df,left_on='Title',right_on='title',how='inner')
joint_data=joint_data.sort_values(by='Rating', ascending=False)





#Top rated 10 movies in Netflix are:
import plotly.express as px
top_rated=joint_data[0:10]
fig =px.sunburst(
    top_rated,
    path=['title','country'],
    values='Rating',
    color='Rating')
fig.show()





# Top países que generan contenido en Netflix
country_count = netflix_df['country'].value_counts().sort_values(ascending=False)
country_count = pd.DataFrame(country_count)
topcountries = country_count.head(11)
topcountries





Last_fifteen_years = netflix_df[netflix_df['release_year']>2005 ]
Last_fifteen_years.head()


plt.figure(figsize=(12,10))
sns.set(style="darkgrid")
ax = sns.countplot(y="release_year", 
data=Last_fifteen_years,
palette="Set1", 
order=netflix_df['release_year'].value_counts().index[0:15])





countries = {}
tv_shows = netflix_df[netflix_df['type'] == 'TV Show']
tv_shows['country'] = tv_shows['country'].fillna('Unknown')
cou = list(tv_shows['country'])

for i in cou:
    i = list(i.split(','))
    if len(i) == 1:
        country = i[0].strip()
        if country in countries:
            countries[country] += 1
        else:
            countries[country] = 1
    else:
        for j in i:
            j = j.strip()
            if j in countries:
                countries[j] += 1
            else:
                countries[j] = 1


countries_fin={}
for country,no in countries.items():
    country=country.replace(' ','')
    if country in list(countries_fin.keys()):
        countries_fin[country]+=no
    else:
        countries_fin[country]=no
        
countries_fin={k: v for k, v in sorted(countries_fin.items(), key=lambda item: item[1], reverse= True)}


plt.figure(figsize=(8,8))
ax = sns.barplot(x=list(countries_fin.keys())[0:10],y=list(countries_fin.values())[0:10])
ax.set_xticklabels(list(countries_fin.keys())[0:10],rotation = 90)





# Filtrar solo películas
netflix_movies = netflix_df[netflix_df['type'] == 'Movie'].copy()

# Eliminar ' min' solo en filas válidas
netflix_movies = netflix_movies[netflix_movies['duration'].notna()]  # Quita nulos
netflix_movies = netflix_movies[netflix_movies['duration'].str.contains('min', na=False)]  # Solo las que tienen "min"

# Remover el texto ' min' y convertir a entero
netflix_movies['duration'] = netflix_movies['duration'].str.replace(' min', '', regex=False)
netflix_movies['duration'] = netflix_movies['duration'].astype(int)

# Mostrar la columna limpia
netflix_movies['duration']


sns.set(style="darkgrid")
ax=sns.kdeplot(data=netflix_movies['duration'], shade=True)





netflix_shows = netflix_df[netflix_df['type'] == 'TV Show'].copy()

features = ['title', 'duration']
durations = netflix_shows[features].copy()
durations['no_of_seasons'] = durations['duration'].str.replace(' Season', '', regex=False)
durations['no_of_seasons'] = durations['no_of_seasons'].str.replace('s', '', regex=False)


durations['no_of_seasons']=durations['no_of_seasons'].astype(str).astype(int)


#TV shows with largest number of seasons
t=['title','no_of_seasons']
top=durations[t]

top=top.sort_values(by='no_of_seasons', ascending=False)


top20=top[0:20]
top20.plot(kind='bar',x='title',y='no_of_seasons', color='blue')








#Plot description based Recommender (Content Based Recommendations)

netflix_df['description'].head()


#Recommedation System(Content Based)

#Import TfIdfVectorizer from scikit-learn
from sklearn.feature_extraction.text import TfidfVectorizer

#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a', etc.
tfidf = TfidfVectorizer(stop_words='english')

#Replace NaN with an empty string
netflix_df['description'] = netflix_df['description'].fillna('')

#Construct the required TF-IDF matrix by fitting and transforming the data
tfidf_matrix = tfidf.fit_transform(netflix_df['description'])

#Output the shape of tfidf_matrix
tfidf_matrix.shape



#Import linear_kernel
from sklearn.metrics.pairwise import linear_kernel

# Compute the cosine similarity matrix
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)


#Construct a reverse map of indices and movie titles 
indices = pd.Series(netflix_df.index, index=netflix_df['title']).drop_duplicates()


# Function that takes in movie title as input and outputs most similar movies
def get_recommendations(title, cosine_sim=cosine_sim):
    # Get the index of the movie that matches the title
    idx = indices[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar movies
    sim_scores = sim_scores[1:11]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies
    return netflix_df['title'].iloc[movie_indices]


get_recommendations('welcome')


get_recommendations('Avengers: Infinity War')


get_recommendations('Dil Dhadakne Do')


#Filling null values with empty string.
filledna=netflix_df.fillna('')
filledna.head()


#Cleaning the data - making all the words lower case
def clean_data(x):
        return str.lower(x.replace(" ", ""))


#Identifying features on which the model is to be filtered.
features=['title','director','cast','description']
filledna=filledna[features]


for feature in features:
    filledna[feature] = filledna[feature].apply(clean_data)
    
filledna.head()


def create_soup(x):
    return x['title']+ ' ' + x['director'] + ' ' + x['cast'] +' '+ x['description']

filledna['soup'] = filledna.apply(create_soup, axis=1)


# Import CountVectorizer and create the count matrix
from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(filledna['soup'])


# Compute the Cosine Similarity matrix based on the count_matrix
from sklearn.metrics.pairwise import cosine_similarity

cosine_sim2 = cosine_similarity(count_matrix, count_matrix)


# Reset index of our main DataFrame and construct reverse mapping as before
filledna=filledna.reset_index()
indices = pd.Series(filledna.index, index=filledna['title'])


def get_recommendations_new(title, cosine_sim=cosine_sim):
    title=title.replace(' ','').lower()
    idx = indices[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim[idx]))
    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar movies
    sim_scores = sim_scores[1:11]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies
    return netflix_df['title'].iloc[movie_indices]


get_recommendations_new('Welcome', cosine_sim2)


get_recommendations_new('Avengers: Infinity War', cosine_sim2)


get_recommendations_new('Dil Dhadakne Do', cosine_sim2)












